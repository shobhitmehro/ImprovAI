{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import generate_train_sequence, SEQUENCE_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 53)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               317440    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 53)                13621     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331061 (1.26 MB)\n",
      "Trainable params: 331061 (1.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "907/907 [==============================] - 81s 89ms/step - loss: 1.6415 - accuracy: 0.5826\n",
      "Epoch 2/50\n",
      "907/907 [==============================] - 83s 92ms/step - loss: 1.3280 - accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "907/907 [==============================] - 84s 93ms/step - loss: 1.2463 - accuracy: 0.6475\n",
      "Epoch 4/50\n",
      "907/907 [==============================] - 86s 95ms/step - loss: 1.1883 - accuracy: 0.6604\n",
      "Epoch 5/50\n",
      "907/907 [==============================] - 85s 93ms/step - loss: 1.1417 - accuracy: 0.6735\n",
      "Epoch 6/50\n",
      "907/907 [==============================] - 86s 95ms/step - loss: 1.0993 - accuracy: 0.6847\n",
      "Epoch 7/50\n",
      "907/907 [==============================] - 88s 98ms/step - loss: 1.0528 - accuracy: 0.6945\n",
      "Epoch 8/50\n",
      "907/907 [==============================] - 82s 91ms/step - loss: 1.0076 - accuracy: 0.7086\n",
      "Epoch 9/50\n",
      "907/907 [==============================] - 85s 94ms/step - loss: 0.9603 - accuracy: 0.7208\n",
      "Epoch 10/50\n",
      "907/907 [==============================] - 88s 98ms/step - loss: 0.9123 - accuracy: 0.7325\n",
      "Epoch 11/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.8663 - accuracy: 0.7446\n",
      "Epoch 12/50\n",
      "907/907 [==============================] - 87s 95ms/step - loss: 0.8187 - accuracy: 0.7585\n",
      "Epoch 13/50\n",
      "907/907 [==============================] - 86s 95ms/step - loss: 0.7732 - accuracy: 0.7715\n",
      "Epoch 14/50\n",
      "907/907 [==============================] - 83s 92ms/step - loss: 0.7321 - accuracy: 0.7821\n",
      "Epoch 15/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.6925 - accuracy: 0.7933\n",
      "Epoch 16/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.6548 - accuracy: 0.8047\n",
      "Epoch 17/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.6417 - accuracy: 0.8087\n",
      "Epoch 18/50\n",
      "907/907 [==============================] - 90s 99ms/step - loss: 0.6057 - accuracy: 0.8188\n",
      "Epoch 19/50\n",
      "907/907 [==============================] - 92s 102ms/step - loss: 0.5570 - accuracy: 0.8317\n",
      "Epoch 20/50\n",
      "907/907 [==============================] - 97s 107ms/step - loss: 0.5392 - accuracy: 0.8371\n",
      "Epoch 21/50\n",
      "907/907 [==============================] - 101s 112ms/step - loss: 0.5110 - accuracy: 0.8449\n",
      "Epoch 22/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.4917 - accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "907/907 [==============================] - 90s 99ms/step - loss: 0.4719 - accuracy: 0.8562\n",
      "Epoch 24/50\n",
      "907/907 [==============================] - 90s 100ms/step - loss: 0.4453 - accuracy: 0.8633\n",
      "Epoch 25/50\n",
      "907/907 [==============================] - 93s 102ms/step - loss: 0.4259 - accuracy: 0.8702\n",
      "Epoch 26/50\n",
      "907/907 [==============================] - 88s 97ms/step - loss: 0.4053 - accuracy: 0.8749\n",
      "Epoch 27/50\n",
      "907/907 [==============================] - 89s 98ms/step - loss: 0.3883 - accuracy: 0.8800\n",
      "Epoch 28/50\n",
      "907/907 [==============================] - 88s 97ms/step - loss: 0.3767 - accuracy: 0.8831\n",
      "Epoch 29/50\n",
      "907/907 [==============================] - 82s 90ms/step - loss: 0.3621 - accuracy: 0.8876\n",
      "Epoch 30/50\n",
      "907/907 [==============================] - 85s 93ms/step - loss: 0.3388 - accuracy: 0.8961\n",
      "Epoch 31/50\n",
      "907/907 [==============================] - 88s 98ms/step - loss: 0.3346 - accuracy: 0.8958\n",
      "Epoch 32/50\n",
      "907/907 [==============================] - 86s 94ms/step - loss: 0.3257 - accuracy: 0.8985\n",
      "Epoch 33/50\n",
      "907/907 [==============================] - 80s 88ms/step - loss: 0.3153 - accuracy: 0.9020\n",
      "Epoch 34/50\n",
      "907/907 [==============================] - 81s 89ms/step - loss: 0.3028 - accuracy: 0.9052\n",
      "Epoch 35/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.2950 - accuracy: 0.9094\n",
      "Epoch 36/50\n",
      "907/907 [==============================] - 96s 106ms/step - loss: 0.2823 - accuracy: 0.9110\n",
      "Epoch 37/50\n",
      "907/907 [==============================] - 95s 105ms/step - loss: 0.2738 - accuracy: 0.9136\n",
      "Epoch 38/50\n",
      "907/907 [==============================] - 95s 104ms/step - loss: 0.2693 - accuracy: 0.9152\n",
      "Epoch 39/50\n",
      "907/907 [==============================] - 89s 98ms/step - loss: 0.2559 - accuracy: 0.9185\n",
      "Epoch 40/50\n",
      "907/907 [==============================] - 92s 101ms/step - loss: 0.2608 - accuracy: 0.9174\n",
      "Epoch 41/50\n",
      "907/907 [==============================] - 92s 102ms/step - loss: 0.2540 - accuracy: 0.9185\n",
      "Epoch 42/50\n",
      "907/907 [==============================] - 78s 86ms/step - loss: 0.2370 - accuracy: 0.9257\n",
      "Epoch 43/50\n",
      "907/907 [==============================] - 84s 93ms/step - loss: 0.2382 - accuracy: 0.9235\n",
      "Epoch 44/50\n",
      "907/907 [==============================] - 83s 91ms/step - loss: 0.3400 - accuracy: 0.8996\n",
      "Epoch 45/50\n",
      "907/907 [==============================] - 83s 92ms/step - loss: 0.2787 - accuracy: 0.9105\n",
      "Epoch 46/50\n",
      "907/907 [==============================] - 80s 89ms/step - loss: 0.2122 - accuracy: 0.9329\n",
      "Epoch 47/50\n",
      "907/907 [==============================] - 88s 97ms/step - loss: 0.2734 - accuracy: 0.9139\n",
      "Epoch 48/50\n",
      "907/907 [==============================] - 87s 96ms/step - loss: 0.2506 - accuracy: 0.9205\n",
      "Epoch 49/50\n",
      "907/907 [==============================] - 91s 100ms/step - loss: 0.2039 - accuracy: 0.9349\n",
      "Epoch 50/50\n",
      "907/907 [==============================] - 88s 98ms/step - loss: 0.2051 - accuracy: 0.9340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shobhitmehrotra/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = \"model.keras\"\n",
    "\n",
    "# Functional API in keras\n",
    "def build_model(output_units,num_units, loss, learning_rate):\n",
    "    # None -> to generate melodies of any length \n",
    "    input = keras.layers.Input(shape=(None, output_units))\n",
    "    x = keras.layers.LSTM(num_units[0])(input)\n",
    "    #avoid overfititng\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    output = keras.layers.Dense(output_units, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(input, output)\n",
    "    model.compile(loss=loss, optimizer=keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train():\n",
    "    inputs, targets = generate_train_sequence(SEQUENCE_LEN)\n",
    "\n",
    "    model = build_model(output_units=53,num_units=[256], loss=\"sparse_categorical_crossentropy\", learning_rate=0.001)\n",
    "\n",
    "    model.fit(inputs, targets, epochs=50, batch_size=64)\n",
    "    model.save(SAVE_PATH)\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
